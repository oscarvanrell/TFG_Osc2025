---
title: "Untitled"
format: html
editor: visual
---

```{r}
rm(list=ls())
library(tidyverse)
library(spdep)
library(spatialreg)
library(gamlss)
library(sphet)
library(xtable)
library(ggspatial)

library(readxl)
```

```{r, eval=FALSE, echo=FALSE}
library(readr)
Poblacion <- read_delim("C:/Users/UIB/Downloads/Poblacion.csv", 
    delim = ";", escape_double = FALSE, locale = locale(decimal_mark = ",", 
        grouping_mark = "."), trim_ws = TRUE)

IPC_Grupos <- read_delim("C:/Users/UIB/Downloads/IPCgrupos.csv", 
    delim = ";", escape_double = FALSE, locale = locale(decimal_mark = ",", 
        grouping_mark = "."), trim_ws = TRUE)

Nacimientos <- read_delim("C:/Users/UIB/Downloads/Nacimientos.csv", 
    delim = ";", escape_double = FALSE, locale = locale(decimal_mark = ",", 
        grouping_mark = "."), trim_ws = TRUE)

save(IPC_Grupos, Nacimientos, Poblacion, file="DatosIniciales.RData")
```

```{r}

load("DatosIniciales.RData")

#cargamos los datos del mapa
pov<-read_sf("shapefiles_provincias_espana/shapefiles_provincias_espana.shp", , options = "ENCODING=UTF8")

nacimientos_2020M01 <- Nacimientos %>%
  filter(Periodo == "2020M01") %>%
  filter(Provincias != "Total") 
  # Separar la columna Provincias en codigo_provincia y nombre_provincia
  #separate(Provincias, into = c("codigo_provincia", "nombre_provincia"), sep = " ", extra = "merge")
#head(nacimientos_2020M01,10)

#preparamos datos de poblacion

poblacion_2020M01 <- Poblacion %>%
  filter(`Edad simple` == "Todas las edades") %>%
  filter(Provincias != "Total Nacional") %>%
  filter(Sexo == "Total") %>%
  filter(Periodo == "1 de enero de 2020")
#head(poblacion_2020M01,10)

#preparams datos de IPC
IPC_2020M01 <- IPC_Grupos %>%
  filter(`Grupos ECOICOP` == "Índice general") %>%
  filter(Provincias != "Nacional") %>%
  filter(`Tipo de dato` == "Índice") %>%
  filter(Periodo == "2020M01")
#head(IPC_2020M01,10)

#Unimos los datos
datos <- merge(x=nacimientos_2020M01, y=poblacion_2020M01, 
                    by.x="Provincias", by.y="Provincias", all.x=TRUE)

#colnames(datos)
datos <- merge(x=datos, y=IPC_2020M01, 
                    by.x="Provincias", by.y="Provincias", all.x=TRUE) %>%
  select(Provincias, Periodo.x, Total.x, Total.y, Total) %>%
  rename(Periodo = Periodo.x, Total.Nacimientos = Total.x, Total.Poblacion = Total.y,  Total.IPC=Total) %>%
  # Separar la columna Provincias en codigo_provincia y nombre_provincia
  separate(Provincias, into = c("codigo_provincia", "nombre_provincia"), sep = " ", extra = "merge")
#colnames(datoss)

#unimos con el mapa
pov2 <- merge(x=pov, y=datos, 
                    by.x="codigo", by.y="codigo_provincia", all.x=TRUE) %>% 
  mutate(tasaNaci = 1E5*Total.Nacimientos/Total.Poblacion)
colnames(pov2)
```

```{r}
#CREACION DEL MAPA
p1 <- ggplot()+geom_sf(data=pov2, aes(fill = tasaNaci))+
  coord_sf()

p1 <- p1 +ggspatial::annotation_scale(
  location = "tl",
  bar_cols = c("grey60", "white")
) +
  ggspatial::annotation_north_arrow(
    location = "bl", which_north = "true",
    pad_x = unit(0, "in"), pad_y = unit(0, "in"),
    style = ggspatial::north_arrow_nautical(
      fill = c("grey40", "white"),
      line_col = "grey20"
    )
  )+
  xlab("Longitude")+
  ylab("Latitude")+
  scale_fill_gradientn(colours = c("darkred", "orange",
                                   "yellow"),
                       name = "Nacimientos 2020M01", ,na.value="white")

p1
ggsave("NacimientosSpain.pdf",p1, dpi=320)
```

```{r}
#TERRAPLANISTA

##pov<- spTransform(pov, CRS("+proj=longlat +datum=NAD83"))
#Matriz de pesos espaciales
sf_use_s2(FALSE)

pov2 <- pov2 %>% dplyr::filter(!is.na(Total.Nacimientos))
```

```{r}
#CALCULA VECINOS DE TODO POLIGONO (1 SI, 0 NO)

#pov<-pov[!is.na(pov@data$GINI),]
### Matriz de vecinos

cont.nb <- spdep::poly2nb(pov2) 	# from the spdep:: package

```

```{r}
#CREA LA W ESTANDARIZADA PARA EL SARAR

cont.listw <- nb2listw(cont.nb, style="W",zero.policy=T)		# from the spdep:: package

par(mfrow=c(1,2))

# PARA VER DEPENDENCIA ESPACIAL (AUTOCORRELACION ESPACIAL)
moran.plot(pov2$tasaNaci,listw = cont.listw,zero.policy = T)
moran.test(pov2$tasaNaci,listw = cont.listw,zero.policy = T)
# SI NO HAY DEPENDENCIA ESPACIAL ES EQUIVALENTE A PERMUTACIONES (DA IGUAL SI ES ALICANTE O ALBACETE) 
```
EN NUESTRO CASO, TENEMOS UN MORAN'S I ALTO Y POSITIVO (3.4) LO QUE INDICA QUE VALORES SIMILARES ESTAN CERCA UNOS DE OTROS. ADEMÁS COMO EL P-VALOR ES <0.05 INDICA PRESENCIA DE AUTOCORRELACION ESPACIAL SIGNIFICATIVA (LA DISTRIBUCION DE LOS DATOS NO ES ALEATORIA Y EXISTE PATRON ESPACIAL).

EN NUESTRO CASO EL P-VALOR ES \>0.05 ASI QUE NO SE RECHAZA LA HIPÓTESIS NULA, LO QUE SUGIERE AUSENCIA DE AUTOCORRELACIÓN ESPACIAL (LOS VALORES DISTRIBUIDOS ALEATORIAMENTE)

```{r}
names(pov2)

```

# Un SEM

```{r}
m<-errorsarlm(tasaNaci~Total.IPC,
              data=pov2,list=cont.listw,zero.policy = T)

summary(m,Nagelkerke=T)
```
Interpretación del SEM:
- Residuals: diferencia entre los valores observados y los predichos por el modelo. Deberian estar distribuidos de forma aleatoria cercanos a 0 indicando que el modelo se ajusta bien a los datos (parece que nuestro caso no tiene mala pinta).

- Lambda: influencia de la dependencia espacial entre las observaciones. Si es distinto a 0 sugiere que hay una dependencia espacial significativa entre las observaciones, observaciones cercanas entre si tienen valores mas similares que las distintas. (en nuestro caso es grande 0.86 y se ve reflejado en el mapa como comentó Alirio)

- LR test value: compara el modelo ajustado con un modelo nulo sin variables explicativas. Si el p valor es bajo (<0.05) el modelo ajustado es mejor que el nulo (en nuestro caso el modelo ajustado es mejor que el nulo por tener p-valor 2.22e-16)

- Log likelihood: medida de la bondad de ajuste del modelo. Cuanto mayor sea mejor se ajusta el modelo a los datos.

- ML Residual Variance: da una medida de la dispersión de los errores del modelo. Una varianza residual más pequeña implica que los errores del modelo son más pequeños, lo que indica que el modelo se ajusta mejor a los datos. Debe interpretarse segun el contexto.

- pseudo-R-cuadrado de Nagelkerke: versión ajustada del R-cuadrado para modelos no lineales y espaciales. Un valor cercano a 1 indica un buen ajuste del modelo, mientras que un valor cercano a 0 sugiere que el modelo no explica bien la variabilidad de los datos.

- AIC: es una medida de la calidad del modelo, que penaliza modelos con muchos parámetros. Cuanto más bajo sea el AIC, mejor es el modelo, en términos de ajuste y simplicidad. Tambien lo compara con el modelo clasico (lm), y vemos que es ligeramente mejor que este.

```{r}
res_sem<-residuals(m)
moran.plot(res_sem,listw = cont.listw,zero.policy = T)
moran.test(res_sem,listw = cont.listw,zero.policy = T)
```

# Un SAR 




```{r}
lagsar<- lagsarlm(tasaNaci~Total.IPC,
                  data=pov2,list=cont.listw,zero.policy = T)

summary(lagsar)
```
INTERPRETACION SAR:

- rho: coeficiente de autocorrelación espacial de la variable dependiente. Mide cuánto afecta el valor de tasaNaci en una región al valor en regiones vecinas. (en nuestro caso rho es negativo (-0.15), lo cual sugiere una relación espacial inversa débil, cuando aumenta la tasa en un lugar, podría disminuir en sus vecinos).

Tests sobre rho:
- Wald statistic: evalua el caso de rho=0, i.e. si no hay autocorrelacion espacial significativa en la var dependiente. Responde a la pregunta de si vale la pena tener un modelo SAR en lugar de uno lineal simple. (en nuestro caso el p-valor es alto lo que sugiere que el componente espacial rho no es significativamente distinto a 0 y que el SAR no mejora tanto sobre uno lineal).

- z-value: lo mismo pero usa una aproximacion normal en luegar de una chi-cuadrado (en nuestro caso tampoco encuentra evidencia para decir que rho es distinto de 0).

- LR test value: lo compara con el modelo lineal sin componente espacial (en nuestro caso vuelve a decir qeu no mejora)


- LM test for residual autocorrelation: indica si los residuos del modelo clasico (lm) presentan autocorrelación espacial para justificar el uso de un modelo espacial. p-valor pequeño implica autocorrelacion espacial significativa. (en nuestro caso pese a que rho no sale significativo, si existe autocorrelacion espacial en los datos)


```{r}
spatialreg::impacts(lagsar, listw=cont.listw, R=1000)
```
```{r}
res_sar<-residuals(lagsar)
moran.plot(res_sar,listw = cont.listw,zero.policy = T)
moran.test(res_sar,listw = cont.listw,zero.policy = T)
```

# Un SARAR

```{r}
sarar<-sacsarlm(tasaNaci~Total.IPC,
                data=pov2,listw =cont.listw,zero.policy = T)

summary(sarar)
```
INTERPRETACION SARAR:

-rho: autocorrelacion espacial en la var dependiente. En nuestro caso al ser negativo sugiere que una region de tasa alta esta rodeada de regiones de tasas bajas y viceversa y el p-valor es pequeño lo qu eimplica que es significativo.

- lambda: autocorrelacion espacial en los errores: tenemos alta autocorrelacion espacial en los errores.

En este caso el LR test value indica que es mejor que un modelo lineal y el AIC mejora con respecto al modelo estandar (lm)


```{r}
res_sarar<-residuals(sarar)
moran.plot(res_sarar,listw = cont.listw,zero.policy = T)
moran.test(res_sarar,listw = cont.listw,zero.policy = T)

```
### Comparacion

Podriamos decir que el SARAR es el que mejor se ajusta teniendo en cuenta el valor de AIC.


```{r}
#esto de mas aporta?
matstand=nb2mat(cont.nb, zero.policy = TRUE)
wt1<-matstand
W=wt1



h_sarar<-spreg(tasaNaci~Total.IPC,data=pov2,
               listw =wt1,model="sarar",het=T)

summary(h_sarar)
```

```{r}
res_sarar_h<-residuals(h_sarar)
moran.plot(res_sarar_h,listw = cont.listw,zero.policy = T)
moran.test(res_sarar_h,listw = cont.listw,zero.policy = T)
```

